{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b199504e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dcc02d544d94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0memoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "import plotly.express as px\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "457f012b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\PREM' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdbdb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\PREM' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14440562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.1.1-cp39-cp39-win_amd64.whl (153 kB)\n",
      "     -------------------------------------- 153.3/153.3 kB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from wordcloud) (1.20.3)\n",
      "Requirement already satisfied: pillow in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from wordcloud) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from wordcloud) (3.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\pothu\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1bb395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startsWithDateAndTime(s):\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -' \n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f529892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAuthor(s):\n",
    "  s=s.split(\":\")\n",
    "  if len(s)==2:\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ca55c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPoint(line):   \n",
    "    splitLine = line.split(' - ') \n",
    "    dateTime = splitLine[0]\n",
    "    date, time = dateTime.split(', ') \n",
    "    message = ' '.join(splitLine[1:])\n",
    "    if FindAuthor(message): \n",
    "        splitMessage = message.split(': ') \n",
    "        author = splitMessage[0] \n",
    "        message = ' '.join(splitMessage[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93f59d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data = [] # List to keep track of data so it can be used by a Pandas dataframe\n",
    "conversation = 'whatsapp-chat-data.txt'\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n",
    "    messageBuffer = [] \n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline() \n",
    "        if not line: \n",
    "            break\n",
    "        line = line.strip() \n",
    "        if startsWithDateAndTime(line): \n",
    "            if len(messageBuffer) > 0: \n",
    "                data.append([date, time, author, ' '.join(messageBuffer)]) \n",
    "            messageBuffer.clear() \n",
    "            date, time, author, message = getDataPoint(line) \n",
    "            messageBuffer.append(message) \n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9deb2cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Author</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13633</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:27 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13634</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:46 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Lucky u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13635</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>Darshan brooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13636</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>Yeh kar na dost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13637</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13638</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13639</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>+91 73032 50500</td>\n",
       "      <td>Mil jayegaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:47 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Okk mene pehle kiya tha firse?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13641</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:49 am</td>\n",
       "      <td>Shubham Chettiar (TSEC CS, TE)</td>\n",
       "      <td>Yeah, many people tried this in the morning an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13642</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:49 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Okk firse karte hai...hope so mil jaye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13643</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:50 am</td>\n",
       "      <td>Shubham Chettiar (TSEC CS, TE)</td>\n",
       "      <td>Yess🤞</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:52 am</td>\n",
       "      <td>Tanay Kamath (TSEC, CS)</td>\n",
       "      <td>Amen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13645</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:56 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Kiya lets see aate hai kya credits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13646</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:58 am</td>\n",
       "      <td>Tanay Kamath (TSEC, CS)</td>\n",
       "      <td>....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13647</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>1:58 am</td>\n",
       "      <td>Tanay Kamath (TSEC, CS)</td>\n",
       "      <td>Bhai lab pe 5-10 mins spend kiye na?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13648</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2:05 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>7mins ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13649</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2:05 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>MCQs mark kiya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13650</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2:05 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Sign-in kiya😂😅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13651</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2:11 am</td>\n",
       "      <td>Tanay Kamath (TSEC, CS)</td>\n",
       "      <td>Incognito se na?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13652</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>2:28 am</td>\n",
       "      <td>Darshan Rander (TSEC, IT)</td>\n",
       "      <td>Yup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Time                          Author  \\\n",
       "13633 2020-02-10  1:27 am                 +91 73032 50500   \n",
       "13634 2020-02-10  1:46 am       Darshan Rander (TSEC, IT)   \n",
       "13635 2020-02-10  1:47 am                 +91 73032 50500   \n",
       "13636 2020-02-10  1:47 am                 +91 73032 50500   \n",
       "13637 2020-02-10  1:47 am                 +91 73032 50500   \n",
       "13638 2020-02-10  1:47 am                 +91 73032 50500   \n",
       "13639 2020-02-10  1:47 am                 +91 73032 50500   \n",
       "13640 2020-02-10  1:47 am       Darshan Rander (TSEC, IT)   \n",
       "13641 2020-02-10  1:49 am  Shubham Chettiar (TSEC CS, TE)   \n",
       "13642 2020-02-10  1:49 am       Darshan Rander (TSEC, IT)   \n",
       "13643 2020-02-10  1:50 am  Shubham Chettiar (TSEC CS, TE)   \n",
       "13644 2020-02-10  1:52 am         Tanay Kamath (TSEC, CS)   \n",
       "13645 2020-02-10  1:56 am       Darshan Rander (TSEC, IT)   \n",
       "13646 2020-02-10  1:58 am         Tanay Kamath (TSEC, CS)   \n",
       "13647 2020-02-10  1:58 am         Tanay Kamath (TSEC, CS)   \n",
       "13648 2020-02-10  2:05 am       Darshan Rander (TSEC, IT)   \n",
       "13649 2020-02-10  2:05 am       Darshan Rander (TSEC, IT)   \n",
       "13650 2020-02-10  2:05 am       Darshan Rander (TSEC, IT)   \n",
       "13651 2020-02-10  2:11 am         Tanay Kamath (TSEC, CS)   \n",
       "13652 2020-02-10  2:28 am       Darshan Rander (TSEC, IT)   \n",
       "\n",
       "                                                 Message  \n",
       "13633                                    <Media omitted>  \n",
       "13634                                            Lucky u  \n",
       "13635                                      Darshan brooo  \n",
       "13636                                    Yeh kar na dost  \n",
       "13637                                                 ..  \n",
       "13638                                                 ..  \n",
       "13639                                        Mil jayegaa  \n",
       "13640                     Okk mene pehle kiya tha firse?  \n",
       "13641  Yeah, many people tried this in the morning an...  \n",
       "13642             Okk firse karte hai...hope so mil jaye  \n",
       "13643                                              Yess🤞  \n",
       "13644                                               Amen  \n",
       "13645                 Kiya lets see aate hai kya credits  \n",
       "13646                                               ....  \n",
       "13647               Bhai lab pe 5-10 mins spend kiye na?  \n",
       "13648                                           7mins ig  \n",
       "13649                                     MCQs mark kiya  \n",
       "13650                                     Sign-in kiya😂😅  \n",
       "13651                                   Incognito se na?  \n",
       "13652                                                Yup  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "136aa6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, '+91 96536 93868', 'Dheeraj Lalwani (TSEC, CS)',\n",
       "       '+91 99201 75875', '+91 95949 08570', '+91 79778 76844',\n",
       "       '+91 90499 38860', 'Tanay Kamath (TSEC, CS)', 'Saket (TSEC, CS)',\n",
       "       '+91 77568 95072', 'Rohit Pathak (TSEC, CS)', '+91 75078 05454',\n",
       "       'Darshan Rander (TSEC, IT)', '+91 79774 68083', '+91 70394 60876',\n",
       "       '+91 96191 55044', '+91 90678 93300', 'Mohit Varma (TSEC, CS)',\n",
       "       '+91 79770 56210', 'Chirag Sharma (TSEC, CS)',\n",
       "       'Vivek Iyer (TSEC, Biomed)', 'Tushar Nankani', '+91 81696 22410',\n",
       "       '+91 89764 07509', '+91 78758 66747', 'Ankit (TSEC, CS)',\n",
       "       '+91 86556 33169', '+91 76663 28147', '+91 88284 70904',\n",
       "       '+91 97698 67348', 'Vivek (TSEC, CS)', 'Hardik Raheja (TSEC, CS)',\n",
       "       '+91 91680 38866', 'Mittul Dasani (TSEC, CS)',\n",
       "       'Kartik Soneji (TSEC, CS)', '+91 77180 43697', '+91 99676 84479',\n",
       "       'Shreya (TSEC, IT)', '+91 96190 16721', '+91 89833 85127',\n",
       "       '+91 99675 58551', '+91 90822 59476', 'Prithvi Rohira (TSEC, CS)',\n",
       "       '+91 90820 98830', 'Mohammed (TSEC, EXTC)', '+91 96992 89993',\n",
       "       '+91 83690 21693', '+91 75064 86714', 'Pratik K (TSEC CS, SE)',\n",
       "       'Farhan Irani (TSEC IT, SE)', '+91 77000 27264',\n",
       "       'Harsh Kapadia (TSEC IT, SE)', 'Saurav Upoor (TSEC CS, SE)',\n",
       "       '+91 77180 82108', '+91 86559 19035', '+91 77150 51136',\n",
       "       '+91 91671 28174', '+91 84335 18102', '+91 84529 62233',\n",
       "       '+91 81080 96759', '+91 82080 02653', '+91 93243 92133',\n",
       "       '+91 97681 67131', '+91 98206 01141', '+91 84540 03063',\n",
       "       '+91 99693 94098', '+91 88305 26885', '+91 70208 31915',\n",
       "       '+91 97027 35002', '+91 98192 22032', '+91 97739 65140',\n",
       "       '+91 97571 15289', 'Rishab Saini (TSEC CS, TE)', '+91 94208 78848',\n",
       "       '+91 93598 18687', '+91 73043 57388', '+91 98331 51331',\n",
       "       '+91 80979 84068', '+91 99697 55118', '+91 95119 48511',\n",
       "       '+91 82916 21138', '+91 98337 61116', '+91 88889 97733',\n",
       "       '+91 97697 60869', '+91 99672 39663', '+91 87796 70896',\n",
       "       '+91 98191 73361', '+91 70219 80066', '+91 88282 22720',\n",
       "       '+91 97027 04646', '+91 70450 40641', '+91 87796 52381',\n",
       "       '+91 99204 26955', '+91 99696 99151', '+91 98333 66146',\n",
       "       '+91 91363 39446', '+91 95940 62134', '+91 77189 86205',\n",
       "       '+91 97694 89970', '+91 99302 21772', '+91 77109 79055',\n",
       "       '+91 96648 44643', '+91 98337 47258', 'Keyul Jain (TSEC, CS)',\n",
       "       '+91 98198 16330', '+91 92842 87810', '+91 72495 29889',\n",
       "       '+91 88798 05171', '+91 91677 97590', '+91 86528 77025',\n",
       "       '+91 77158 99478', '+91 77383 38799',\n",
       "       'Shubham Chettiar (TSEC CS, TE)', 'Trushant Narwani (TSEC, CS)',\n",
       "       '+91 86059 72817', '+91 83292 66084', '+91 82080 03744',\n",
       "       '+91 98670 44401', '+91 77098 73262', 'Sahil A (TSEC, CS-B)',\n",
       "       '+91 96194 00980', '+91 99304 97064', '+91 77699 70908',\n",
       "       '+91 98337 26449', '+91 97847 88658', '+91 82916 40581',\n",
       "       '+91 91670 43943', '+91 94044 50783', '+91 90821 58843',\n",
       "       '+91 97022 69539', '+91 73036 41107', '+91 88795 52797',\n",
       "       'Akash Khatri (TSEC, CS)', '+91 91525 25452', '+91 79778 03985',\n",
       "       '+91 91725 67828', '+91 98206 14506', '+91 70218 25025',\n",
       "       '+91 94200 70678', '+91 99203 34360', '+91 96374 40537',\n",
       "       '+91 98199 01072', '+91 91673 86883', '+91 73032 50500',\n",
       "       '+91 91362 39673', '+91 98501 32687', 'Kritanjali',\n",
       "       '+91 98709 38217'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3179fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n",
      "4572\n",
      "Data science Community\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'total_messages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22216/775348015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data science Community\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Messages:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtotal_messages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Media:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmedia_messages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Emojis:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0memojis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_messages' is not defined"
     ]
    }
   ],
   "source": [
    "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
    "print(media_messages)\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.EMOJI_DATA for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: re.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "print(\"Data science Community\")\n",
    "print(\"Messages:\",total_messages)\n",
    "print(\"Media:\",media_messages)\n",
    "print(\"Emojis:\",emojis)\n",
    "print(\"Links:\",links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "017a839b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji==1.7.0\n",
      "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
      "     -------------------------------------- 175.4/175.4 kB 2.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py): started\n",
      "  Building wheel for emoji (setup.py): finished with status 'done'\n",
      "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171059 sha256=c73505dfc51eb8555eb025bdac73102e12236d91fb784f6bb3a19e91b91b8201\n",
      "  Stored in directory: c:\\users\\pothu\\appdata\\local\\pip\\cache\\wheels\\fa\\7a\\e9\\22dd0515e1bad255e51663ee513a2fa839c95934c5fc301090\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "  Attempting uninstall: emoji\n",
      "    Found existing installation: emoji 2.2.0\n",
      "    Uninstalling emoji-2.2.0:\n",
      "      Successfully uninstalled emoji-2.2.0\n",
      "Successfully installed emoji-1.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install emoji==1.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be3af3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12966 entries, 0 to 13652\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   Date      12966 non-null  datetime64[ns]\n",
      " 1   Time      12966 non-null  object        \n",
      " 2   Author    11889 non-null  object        \n",
      " 3   Message   12966 non-null  object        \n",
      " 4   emoji     12966 non-null  object        \n",
      " 5   urlcount  12966 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(4)\n",
      "memory usage: 709.1+ KB\n",
      "Stats of Aman Kharwal -\n",
      "Messages Sent 0\n",
      "Words per message nan\n",
      "Media Messages Sent 0\n",
      "Emojis Sent 0\n",
      "Links Sent 0\n",
      "\n",
      "Stats of Sahil Pansare -\n",
      "Messages Sent 0\n",
      "Words per message nan\n",
      "Media Messages Sent 0\n",
      "Emojis Sent 0\n",
      "Links Sent 0\n",
      "\n",
      "Stats of Sumehar -\n",
      "Messages Sent 0\n",
      "Words per message nan\n",
      "Media Messages Sent 0\n",
      "Emojis Sent 0\n",
      "Links Sent 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pothu\\AppData\\Local\\Temp/ipykernel_22216/479309310.py:17: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n"
     ]
    }
   ],
   "source": [
    "media_messages_df = df[df['Message'] == '<Media omitted>']\n",
    "messages_df = df.drop(media_messages_df.index)\n",
    "messages_df.info()\n",
    "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "messages_df[\"MessageCount\"]=1\n",
    "\n",
    "l = [\"Aman Kharwal\", \"Sahil Pansare\", \"Sumehar\"]\n",
    "for i in range(len(l)):\n",
    "  # Filtering out messages of particular user\n",
    "  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
    "  # req_df will contain messages of only one particular user\n",
    "  print(f'Stats of {l[i]} -')\n",
    "  # shape will print number of rows which indirectly means the number of messages\n",
    "  print('Messages Sent', req_df.shape[0])\n",
    "  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
    "  print('Words per message', words_per_message)\n",
    "  #media conists of media messages\n",
    "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
    "  print('Media Messages Sent', media)\n",
    "  # emojis conists of total emojis\n",
    "  emojis = sum(req_df['emoji'].str.len())\n",
    "  print('Emojis Sent', emojis)\n",
    "  #links consist of total links\n",
    "  links = sum(req_df[\"urlcount\"])   \n",
    "  print('Links Sent', links)   \n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f097d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('😂', 1896)\n",
      "('👍', 259)\n",
      "('🔥', 254)\n",
      "('😅', 224)\n",
      "('💯', 185)\n",
      "('🤣', 132)\n",
      "('👍🏻', 99)\n",
      "('🤦\\u200d♂️', 83)\n",
      "('👏', 74)\n",
      "('🙏', 62)\n",
      "('🙌🏻', 52)\n",
      "('😭', 48)\n",
      "('🤔', 37)\n",
      "('🤩', 32)\n",
      "('👌', 29)\n",
      "('❤️', 29)\n",
      "('🙄', 28)\n",
      "('👏🏻', 26)\n",
      "('🤦\\u200d♂', 25)\n",
      "('✨', 23)\n",
      "('🙈', 22)\n",
      "('👌🏻', 22)\n",
      "('🙌', 21)\n",
      "('😢', 21)\n",
      "('🤦🏻\\u200d♂️', 21)\n",
      "('🤯', 18)\n",
      "('😍', 18)\n",
      "('😁', 16)\n",
      "('👌🏼', 16)\n",
      "('🥳', 15)\n",
      "('🙏🏻', 14)\n",
      "('🤷🏻\\u200d♂️', 14)\n",
      "('💻', 13)\n",
      "('🙁', 12)\n",
      "('😎', 12)\n",
      "('✅', 11)\n",
      "('🥺', 11)\n",
      "('✌️', 11)\n",
      "('😓', 11)\n",
      "('⚒', 11)\n",
      "('🎉', 10)\n",
      "('🙃', 10)\n",
      "('💪🏻', 10)\n",
      "('🤷\\u200d♂️', 10)\n",
      "('👉🏾', 10)\n",
      "('👨\\u200d💻', 9)\n",
      "('🔸', 9)\n",
      "('⚡️', 9)\n",
      "('⚡', 9)\n",
      "('😊', 8)\n",
      "('👨🏻\\u200d💻', 8)\n",
      "('😶', 8)\n",
      "('💪', 8)\n",
      "('🤞', 8)\n",
      "('👉🏻', 8)\n",
      "('😤', 8)\n",
      "('👩🏻\\u200d💻', 7)\n",
      "('🏁', 7)\n",
      "('➡', 7)\n",
      "('👍🏼', 7)\n",
      "('✌', 6)\n",
      "('☝', 6)\n",
      "('📍', 6)\n",
      "('🙂', 6)\n",
      "('❤', 6)\n",
      "('🎂', 6)\n",
      "('😡', 6)\n",
      "('🟢', 6)\n",
      "('🙌🏼', 6)\n",
      "('▪️', 6)\n",
      "('‼️', 6)\n",
      "('👉', 6)\n",
      "('🤨', 5)\n",
      "('🏆', 5)\n",
      "('📌', 5)\n",
      "('⏳', 5)\n",
      "('😋', 5)\n",
      "('🗓', 5)\n",
      "('🔊', 5)\n",
      "('🔴', 5)\n",
      "('👀', 5)\n",
      "('😉', 5)\n",
      "('😱', 5)\n",
      "('💛', 5)\n",
      "('🌟', 5)\n",
      "('😳', 5)\n",
      "('🛑', 5)\n",
      "('🤟', 4)\n",
      "('😄', 4)\n",
      "('😇', 4)\n",
      "('👇🏻', 4)\n",
      "('🔶', 4)\n",
      "('😌', 4)\n",
      "('😃', 4)\n",
      "('🥴', 4)\n",
      "('🤞🏻', 4)\n",
      "('🤮', 4)\n",
      "('😕', 4)\n",
      "('🤗', 4)\n",
      "('⁉️', 4)\n",
      "('➡️', 4)\n",
      "('❓', 4)\n",
      "('👩\\u200d💻', 3)\n",
      "('🖥', 3)\n",
      "('👆', 3)\n",
      "('😐', 3)\n",
      "('🌚', 3)\n",
      "('🧠', 3)\n",
      "('👇', 3)\n",
      "('🤟🏻', 3)\n",
      "('👥', 3)\n",
      "('📈', 3)\n",
      "('💁🏻\\u200d♂', 3)\n",
      "('💰', 3)\n",
      "('🥇', 3)\n",
      "('☝️', 3)\n",
      "('🔵', 3)\n",
      "('🙋🏻\\u200d♂', 3)\n",
      "('🤦🏻\\u200d♂', 3)\n",
      "('✋', 3)\n",
      "('✌🏻', 3)\n",
      "('♥️', 3)\n",
      "('⚠️', 3)\n",
      "('☹️', 3)\n",
      "('🗓️', 3)\n",
      "('🤘🏻', 3)\n",
      "('💫', 3)\n",
      "('😒', 3)\n",
      "('👇🏼', 3)\n",
      "('🕰', 3)\n",
      "('📞', 3)\n",
      "('📝', 3)\n",
      "('👏🏼', 3)\n",
      "('🙏🏼', 3)\n",
      "('🤦', 2)\n",
      "('🎊', 2)\n",
      "('🎖', 2)\n",
      "('🎁', 2)\n",
      "('📢', 2)\n",
      "('💥', 2)\n",
      "('✍🏻', 2)\n",
      "('🤖', 2)\n",
      "('🌐', 2)\n",
      "('📱', 2)\n",
      "('🤜🏻', 2)\n",
      "('💭', 2)\n",
      "('💸', 2)\n",
      "('🤑', 2)\n",
      "('💼', 2)\n",
      "('🤳', 2)\n",
      "('👨\\u200d🎓', 2)\n",
      "('📲', 2)\n",
      "('☝🏻', 2)\n",
      "('😔', 2)\n",
      "('😫', 2)\n",
      "('🤪', 2)\n",
      "('👊🏻', 2)\n",
      "('☠️', 2)\n",
      "('📹', 2)\n",
      "('⛈', 2)\n",
      "('📜', 2)\n",
      "('😜', 2)\n",
      "('🤫', 2)\n",
      "('💡', 2)\n",
      "('❗️', 2)\n",
      "('⬇️', 2)\n",
      "('👈🏻', 2)\n",
      "('🧐', 2)\n",
      "('🕰️', 2)\n",
      "('😛', 2)\n",
      "('😖', 2)\n",
      "('📅', 2)\n",
      "('🏠', 2)\n",
      "('⭐', 2)\n",
      "('🎯', 2)\n",
      "('🥱', 2)\n",
      "('😏', 2)\n",
      "('📚', 2)\n",
      "('👩🏾\\u200d💻', 2)\n",
      "('🤢', 2)\n",
      "('☁️', 2)\n",
      "('⭐️', 2)\n",
      "('😑', 1)\n",
      "('❌', 1)\n",
      "('👆🏻', 1)\n",
      "('☝🏼', 1)\n",
      "('🚂', 1)\n",
      "('‼', 1)\n",
      "('⛓', 1)\n",
      "('🌏', 1)\n",
      "('🙍🏻\\u200d♀', 1)\n",
      "('🙍🏻\\u200d♂', 1)\n",
      "('👨🏻\\u200d🏫', 1)\n",
      "('💁🏻\\u200d♀', 1)\n",
      "('🥈', 1)\n",
      "('🥉', 1)\n",
      "('🏃🏻\\u200d♀', 1)\n",
      "('🏃🏻', 1)\n",
      "('🛍', 1)\n",
      "('🕗', 1)\n",
      "('🏤', 1)\n",
      "('🥤', 1)\n",
      "('🍽', 1)\n",
      "('🛏', 1)\n",
      "('👱🏻\\u200d♀', 1)\n",
      "('👨🏻\\u200d🦰', 1)\n",
      "('👋🏻', 1)\n",
      "('💁', 1)\n",
      "('💁\\u200d♂', 1)\n",
      "('☠', 1)\n",
      "('🤒', 1)\n",
      "('🤚', 1)\n",
      "('🤷🏻\\u200d♂', 1)\n",
      "('🤦🏿\\u200d♂', 1)\n",
      "('🤷🏽\\u200d♂️', 1)\n",
      "('🤙', 1)\n",
      "('📊', 1)\n",
      "('🆓', 1)\n",
      "('😞', 1)\n",
      "('😵', 1)\n",
      "('😯', 1)\n",
      "('🙆🏽\\u200d♂️', 1)\n",
      "('👊', 1)\n",
      "('📽️', 1)\n",
      "('🎥', 1)\n",
      "('⏱', 1)\n",
      "('🤭', 1)\n",
      "('😈', 1)\n",
      "('💨', 1)\n",
      "('😲', 1)\n",
      "('🗒', 1)\n",
      "('🐍', 1)\n",
      "('🔑', 1)\n",
      "('🕘', 1)\n",
      "('🗞', 1)\n",
      "('❗', 1)\n",
      "('📬', 1)\n",
      "('🙍🏻\\u200d♀️', 1)\n",
      "('🤠', 1)\n",
      "('📄', 1)\n",
      "('👨🏻\\u200d💼', 1)\n",
      "('👩🏻\\u200d🎓', 1)\n",
      "('💁🏻\\u200d♀️', 1)\n",
      "('💁🏻\\u200d♂️', 1)\n",
      "('🤳🏻', 1)\n",
      "('🤧', 1)\n",
      "('☺️', 1)\n",
      "('⚠', 1)\n",
      "('😪', 1)\n",
      "('⭕', 1)\n",
      "('⏩', 1)\n",
      "('🕑', 1)\n",
      "('🕔', 1)\n",
      "('☎️', 1)\n",
      "('🤐', 1)\n",
      "('⚔', 1)\n",
      "('🤺', 1)\n",
      "('🕕', 1)\n",
      "('⚰️', 1)\n",
      "('🤕', 1)\n",
      "('🎒', 1)\n",
      "('🤝🏼', 1)\n",
      "('🚶🏻', 1)\n",
      "('🔺', 1)\n",
      "('🔻', 1)\n",
      "('🔗', 1)\n",
      "('🔎', 1)\n",
      "('🚩', 1)\n",
      "('🖥️', 1)\n",
      "('🥂', 1)\n",
      "('🤦🏻', 1)\n",
      "('⚙️', 1)\n",
      "('🌝', 1)\n",
      "('💪🏼', 1)\n",
      "('🕜', 1)\n",
      "('✍', 1)\n",
      "('▶', 1)\n",
      "('😥', 1)\n"
     ]
    }
   ],
   "source": [
    "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
    "emoji_dict = dict(Counter(total_emojis_list))\n",
    "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "for i in emoji_dict:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a10f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 647511 words in all the messages.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22216/1380676891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTOPWORDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Generate a word cloud image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"white\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# Display the generated image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# the matplotlib way:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only supported for TrueType fonts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         bbox = font.getbbox(\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "text = \" \".join(review for review in messages_df.Message)\n",
    "print (\"There are {} words in all the messages.\".format(len(text)))\n",
    "stopwords = set(STOPWORDS)\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f764ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author name Aman Kharwal\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "We need at least 1 word to plot a word cloud, got 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22216/1067439608.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m#Generate a word cloud image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Author name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m   \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"white\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m   \u001b[1;31m#Display the generated image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrequencies\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m             raise ValueError(\"We need at least 1 word to plot a word cloud, \"\n\u001b[0m\u001b[0;32m    411\u001b[0m                              \"got %d.\" % len(frequencies))\n\u001b[0;32m    412\u001b[0m         \u001b[0mfrequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrequencies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: We need at least 1 word to plot a word cloud, got 0."
     ]
    }
   ],
   "source": [
    "l = [\"Aman Kharwal\", \"Sahil Pansare\", \"Sumehar\"]\n",
    "for i in range(len(l)):\n",
    "  dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
    "  text = \" \".join(review for review in dummy_df.Message)\n",
    "  stopwords = set(STOPWORDS)\n",
    "  #Generate a word cloud image\n",
    "  print('Author name',l[i])\n",
    "  wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "  #Display the generated image   \n",
    "  plt.figure( figsize=(10,5))\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885c020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
